{
 "metadata": {
  "name": "",
  "signature": "sha256:8a62c45bc565e3aabdedf213d80f10287043c934ca02289a2d893def368c2519"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Author: CHANDRAMOHAN T N\n",
      "File: Bloom Filter Inclusion.py \n",
      "\"\"\"\n",
      "\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import precision_recall_curve\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn import metrics\n",
      "import sys\n",
      "\n",
      "def Get_data(i_f):\n",
      "    f = open(i_f, 'r')\n",
      "    data = []\n",
      "    while 1:\n",
      "        line = f.readline()\n",
      "        line = line[0:-1]\n",
      "        if len(line) > 0:\n",
      "            items = map(int, line.split(','))\n",
      "            data.append(items)\n",
      "        else:\n",
      "            f.close()\n",
      "            break\n",
      "    return data\n",
      "\n",
      "def Get_labels(i_f):\n",
      "    f = open(i_f, 'r')\n",
      "    labels = []\n",
      "    while 1:\n",
      "        line = f.readline()\n",
      "        line = line[0:-1]\n",
      "        if len(line) > 0:\n",
      "            labels.append(int(line))\n",
      "        else:\n",
      "            f.close\n",
      "            break\n",
      "    return labels\n",
      "\n",
      "def sigmoid(x):\n",
      "    return 1.0 / (1.0 + np.exp(-x))\n",
      "\n",
      "def log_likelihood(x, y, w):\n",
      "    p = sigmoid(np.dot(x, w))\n",
      "    loss = -y * np.log(p) - (1 - y) * np.log(1 - p)\n",
      "    return loss.mean()\n",
      "\n",
      "def gradient(x, y, w):\n",
      "    p = sigmoid(np.dot(x, w))\n",
      "    grad = np.dot(np.transpose(x), (p - y))\n",
      "    return grad.reshape(w.shape)\n",
      "\n",
      "def hashfn(item, n):\n",
      "    h = hash(item)\n",
      "    return (1 << (h%n)) | (1 << (h/n%n))\n",
      "\n",
      "def mask(val, n):\n",
      "    return bin(hashfn(val, n))[2:]\n",
      "\n",
      "def plot(a, b, c, x, l, n):\n",
      "    plt.plot(x, a, 'r', label='AUC Loss')\n",
      "    plt.plot(x, b, 'g', label='Log Loss')\n",
      "    plt.plot(x, c, 'b', label='Sq Error')\n",
      "    plt.title(l)\n",
      "    plt.legend(loc='upper right')\n",
      "    plt.ylabel('Loss')\n",
      "    if n == 1:\n",
      "        plt.xlabel('Iteration')\n",
      "        plt.savefig('Bloom Filter Inclusion Test Loss.png')\n",
      "    else:\n",
      "        plt.xlabel('Count limit')\n",
      "        plt.savefig('Bloom Filter Inclusion Performance.png')\n",
      "    plt.show()\n",
      "    plt.close()\n",
      "\n",
      "\n",
      "class BFI(object):\n",
      "\n",
      "    def __init__(self, x, y):\n",
      "        self.x = np.concatenate((np.ones((len(x), 1)), np.array(x)), axis=1)\n",
      "        self.y = np.array(y).reshape(len(y), 1)\n",
      "        self.w = np.zeros((self.x.shape[1], 1))\n",
      "\n",
      "    def train_ogd(self, l_rate, n, bloom, idx):\n",
      "        x = self.x[idx * 1: (idx+1) * 1]\n",
      "        y = self.y[idx * 1: (idx+1) * 1]\n",
      "        bloom.add(x[0])\n",
      "        indx = [k for k in range(len(x[0])) if bloom.query(k, n) == True]\n",
      "        g = gradient(x, y, self.w)\n",
      "        g_temp = np.zeros((self.w.shape[0], 1))\n",
      "        for l in indx:\n",
      "            g_temp[l] = g[l]\n",
      "        self.w = self.w - l_rate * g_temp\n",
      "        return self.w\n",
      "\n",
      "    def update_weights(self, w):\n",
      "        self.w = w\n",
      "\n",
      "    def save_model(self):\n",
      "        np.savez_compressed('Model_bfi', w=self.w)\n",
      "\n",
      "    def predict(self, x):\n",
      "        labels = np.zeros((len(x), 1))\n",
      "        p = sigmoid(np.dot(x, self.w))\n",
      "        for i in xrange(len(x)):\n",
      "            if p[i] > 0.5:\n",
      "                labels[i] = 1\n",
      "        return p, labels\n",
      "\n",
      "    def evaluate(self, y_pred, y_true, test_x):\n",
      "        fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
      "        auc = metrics.auc(fpr, tpr)\n",
      "        auc_loss = 1 - auc\n",
      "        log_loss = log_likelihood(test_x, y_true, self.w)\n",
      "        sq_error = np.sum((y_pred - y_true)**2) / y_pred.shape[0]\n",
      "        return auc_loss, log_loss, sq_error\n",
      "    \n",
      "    def perf_metrics(self, y_real, y_pred, y_prob):\n",
      "        precision, recall, thresholds = precision_recall_curve(y_real, y_prob)\n",
      "        plt.plot(precision, recall, 'r')\n",
      "        plt.ylabel('Precision')\n",
      "        plt.xlabel('Recall')\n",
      "        plt.savefig('PR_curve_bfi.png')\n",
      "        plt.show()\n",
      "        print('Accuracy:')\n",
      "        print(accuracy_score(y_real, y_pred))\n",
      "        print('Precison : Recall : F-score')\n",
      "        print(precision_recall_fscore_support(y_real, y_pred))\n",
      "\n",
      "class CountingBloom(object):\n",
      "\n",
      "    def __init__(self, n):\n",
      "        self.n = n\n",
      "        self.items = [0] * self.n\n",
      "\n",
      "    def add(self, item):\n",
      "        bits = [mask(str(i), self.n) for i in range(len(item)) if int(item[i]) != 0]\n",
      "        for b in bits:\n",
      "            for index, bit in enumerate(b):\n",
      "                if bit == '1':\n",
      "                    self.items[index] += 1\n",
      "\n",
      "    def query(self, item, n):\n",
      "        bits = mask(str(item), self.n)\n",
      "        nz = np.array(map(int, list(bits))).nonzero()[0]\n",
      "        for index in nz:\n",
      "            if self.items[index] < n:\n",
      "                return False\n",
      "        return True\n",
      "    \n",
      "    def remove(self, item):\n",
      "        bits = mask(item, self.n)\n",
      "        for index, bit in enumerate(bits):\n",
      "            if bit == '1' and self.items[index]:\n",
      "                self.items[index] -= 1\n",
      "\n",
      "def main():\n",
      "    i_f = '../Data/books/Train_x.csv'\n",
      "    train_x = Get_data(i_f)\n",
      "    i_f = '../Data/books/Test_x.csv'\n",
      "    test_x = Get_data(i_f)\n",
      "    test_x = np.concatenate((np.ones((len(test_x), 1)), np.array(test_x)), axis=1)\n",
      "    i_f = '../Data/books/Train_y.csv'\n",
      "    train_y = Get_labels(i_f)\n",
      "    i_f = '../Data/books/Test_y.csv'\n",
      "    test_y = Get_labels(i_f)\n",
      "    test_y = np.reshape(test_y, (test_x.shape[0], 1))\n",
      "\n",
      "    lr = 0.01\n",
      "    max_iter = 15000\n",
      "    n = [i for i in range(1, 6)]\n",
      "    bloom = CountingBloom(int(np.log2(len(train_x[0])))+1)\n",
      "    prev_auc_loss = sys.maxint\n",
      "    te_auc_loss = []\n",
      "    te_log_loss = []\n",
      "    te_sq_error = []\n",
      "    for l in n:\n",
      "        print('n: ' + str(l))\n",
      "        bfi_reg = BFI(train_x, train_y)\n",
      "        tr_auc_loss = []\n",
      "        tr_log_loss = []\n",
      "        tr_sq_error = []\n",
      "        for i in range(max_iter):\n",
      "            idx = np.random.randint(len(train_x))\n",
      "            w = bfi_reg.train_ogd(lr, l, bloom, idx)\n",
      "            bfi_reg.update_weights(w)\n",
      "            if (i+1) % 500 == 0:\n",
      "                y_prob, y_pred = bfi_reg.predict(test_x)\n",
      "                a, b, c = bfi_reg.evaluate(y_prob, test_y, test_x)\n",
      "                tr_auc_loss.append(a)\n",
      "                tr_log_loss.append(b)\n",
      "                tr_sq_error.append(c)\n",
      "        y_prob, y_pred = bfi_reg.predict(test_x)\n",
      "        a, b, c = bfi_reg.evaluate(y_prob, test_y, test_x)\n",
      "        te_auc_loss.append(a)\n",
      "        te_log_loss.append(b)\n",
      "        te_sq_error.append(c)\n",
      "        if a < prev_auc_loss:\n",
      "            prev_auc_loss = a\n",
      "            best_l = l\n",
      "            bfi_reg.save_model()\n",
      "            r = [k for k in range(len(tr_auc_loss))]\n",
      "            plot(tr_auc_loss, tr_log_loss, tr_sq_error, r, 'Bloom Filter Inclusion Test_loss, n= ' + str(best_l), 1)\n",
      "    plot(te_auc_loss, te_log_loss, te_sq_error, n, 'Bloom Filter Inclusion Performance', 2)\n",
      "    a = np.load('Model_l_bfi.npz')\n",
      "    w = a['w']\n",
      "    bfi_reg.update_weights(w)\n",
      "    y_prob, y_pred = bfi_reg.predict(test_x)\n",
      "    bfi_reg.perf_metrics(test_y, y_pred, y_prob)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}